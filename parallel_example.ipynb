{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def3b081-7e38-48e2-b453-f6a0b06dace7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detectd 256 CPUs\n",
      "detectd 1 GPUs\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import os\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import random\n",
    "from parallel_funcs import * # functions must be in another .py file for mp to work\n",
    "\n",
    "# 'spawn' is needed to use gpus in parallel for pytorch\n",
    "#mp.set_start_method('spawn') # uncomment this if running GPU in paralell / using pytorch\n",
    "\n",
    "#print(mp.cpu_count())\n",
    "print('detectd', os.cpu_count(), 'CPUs')\n",
    "print('detectd', th.cuda.device_count(), 'GPUs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d83a4522-5a27-4304-8c80-35edbb75b3f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set these parameters to either run in parallel and how many available gpu/cpu threads\n",
    "run_paralllel = True\n",
    "gpu_threads = th.cuda.device_count()\n",
    "cpu_threads = os.cpu_count()-4 # reserve some empty CPU (play with this value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe72d789-bd78-4148-a2ff-cdc752ffb58a",
   "metadata": {},
   "source": [
    "# prepare data and jobs to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fa50303-7b19-40f1-9341-1a326abd94cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CREATE DUMMY DATA\n",
    "# note: the size of the job depends on if you will receive a boost in parallel time,\n",
    "    # meaning if the job is too small then the overhead of using mp is not worth it and may increase run time\n",
    "    # a way around this is to send threads in batches rather than one at a time\n",
    "matrix_size = 2**15\n",
    "X = np.random.uniform(0, 100, (matrix_size,matrix_size))\n",
    "Y = np.random.uniform(0, 100, (matrix_size,matrix_size))\n",
    "\n",
    "# make trainer object to handle data (do not send data as params)\n",
    "trainer = Trainer(X, Y) # read only on X, Y\n",
    "\n",
    "# job parameters follow this structure:\n",
    "    # [Trainer.job_name, params_dictionary]\n",
    "    # each item above is one job, for example:\n",
    "job1 = ['dummy_func', {'alpha':1, 'beta':2, 'multi_gpu':False}] # set multi_gpu=True if running GPUs in parallel\n",
    "job2 = ['dummy_func', {'alpha':3, 'beta':4, 'multi_gpu':False}] # set multi_gpu=True if running GPUs in parallel\n",
    "\n",
    "# lets make several dummy jobs just to run them ...\n",
    "n_jobs = 2*6\n",
    "job_params = [['dummy_func', {'alpha':random.random(), 'beta':random.random()}] for _ in range(n_jobs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf15309f-f8b7-47d6-9abc-b4bb44caba66",
   "metadata": {},
   "source": [
    "# RUN JOBS IN SERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e898bf4a-ad79-4d21-b8f9-d27a7a273be5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ran jobs in series in 75.11133599281311 seconds\n"
     ]
    }
   ],
   "source": [
    "stopwatch = Stopwatch()\n",
    "# in series, we will just call one method at a time and aggregate results in a list\n",
    "series_results = [trainer.single_job(job_param[0], job_param[1]) for job_param in job_params]\n",
    "print('ran jobs in series in', stopwatch.stop(), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152b249e-39a9-4ca7-be27-bafc37b15001",
   "metadata": {},
   "source": [
    "# RUN JOBS IN PARALLEL (single job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ea24b-498a-42bf-acad-9a1e64af8b72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stopwatch = Stopwatch()\n",
    "# make pool with number of threads \n",
    "pool = mp.Pool(processes=cpu_threads) # processes=gpu_threads if using GPUs in parallel\n",
    "# pool will equally divide the length of the job_params list among all processes\n",
    "# results will be an aggregated list of values returned from calling each method\n",
    "parallel_single_results = pool.starmap(trainer.single_job, job_params) # run_job will pass in method name and run that method with unpacked dictionary of parameters\n",
    "print('ran jobs in parallel (single job) in', stopwatch.stop(), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a411655-5d0c-490d-aa0f-64e25a04a03f",
   "metadata": {},
   "source": [
    "# RUN JOBS IN PARALLEL (batch job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d397d4-2554-44ce-98d8-d4e5550c2287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets put jobs into batches\n",
    "batch_job_params = []\n",
    "batch_size, batch = 4, []\n",
    "for i in range(len(job_params)):\n",
    "    batch.append(job_params[i])\n",
    "    if len(batch) % batch_size == 0 or i == len(job_params)-1:\n",
    "        batch_job_params.append([batch]) # mp executes a method in a thread by unpacking a list of params\n",
    "        batch = []\n",
    "\n",
    "stopwatch = Stopwatch()\n",
    "# make pool with number of threads \n",
    "pool = mp.Pool(processes=cpu_threads) # processes=gpu_threads if using GPUs in parallel\n",
    "# pool will equally divide the length of the job_params list among all processes\n",
    "# results will be an aggregated list of values returned from calling each method\n",
    "batch_results = pool.starmap(trainer.batch_job, batch_job_params) # run_job will pass in method name and run that method with unpacked dictionary of parameters\n",
    "print('ran jobs in parallel (batch job) in', stopwatch.stop(), 'seconds')\n",
    "\n",
    "# flatten batch results\n",
    "parallel_batch_results = []\n",
    "for batch in batch_results:\n",
    "    parallel_batch_results = parallel_batch_results + batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d1c3b-adcc-4203-bfb8-de97b4ea792e",
   "metadata": {},
   "source": [
    "# check accuracy of all 3 methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64323512-8631-455b-aaab-3e43c536af30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('absolute error between all 3 methods =', np.sum(\n",
    "    np.abs(np.array(series_results) - np.array(parallel_single_results)) + np.abs(np.array(series_results) - np.array(parallel_batch_results))\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7f73cf-66a6-4209-8fbf-e675d1a6d6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
